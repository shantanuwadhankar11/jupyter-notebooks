{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "05a4ecc5-5708-47de-beb5-2ef5cf52a6bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import smtplib\n",
    "import os\n",
    "import shutil\n",
    "import math\n",
    "import calendar\n",
    "import re\n",
    "import pandas as pd\n",
    "import concurrent.futures\n",
    "import zipfile\n",
    "import shutil\n",
    "import concurrent.futures\n",
    "import zipfile\n",
    "import shutil\n",
    "import logging\n",
    "import json\n",
    "import requests\n",
    "import tarfile\n",
    "# import paramiko\n",
    "# import openpyxl \n",
    "# import oracledb\n",
    "\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.functions import *\n",
    "from datetime import *\n",
    "from pyspark.sql.window import *\n",
    "from pyspark.sql import Window\n",
    "from pyspark.sql.types import *\n",
    "from delta import DeltaTable\n",
    "from dateutil.relativedelta import relativedelta\n",
    "from email.mime.text import MIMEText\n",
    "from email.mime.multipart import *\n",
    "from io import StringIO\n",
    "from email.mime.application import MIMEApplication\n",
    "from pandas import ExcelWriter\n",
    "from email.mime.base import MIMEBase\n",
    "from email import encoders\n",
    "from tempfile import TemporaryDirectory\n",
    "from datetime import *\n",
    "from pytz import timezone\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import Row\n",
    "from pyspark.sql.functions import col, lit, when, udf\n",
    "from pyspark import SparkContext\n",
    "from pyspark.ml import Estimator, Model\n",
    "from pyspark.ml.feature import VectorAssembler, StringIndexer\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import IntegerType, StringType\n",
    "from pyspark.sql import SQLContext\n",
    "from pyspark.sql import DataFrame\n",
    "# For PySpark MLlib\n",
    "from pyspark.ml.classification import LogisticRegression, DecisionTreeClassifier\n",
    "from pyspark.ml.clustering import KMeans\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator, RegressionEvaluator\n",
    "from pyspark.ml.recommendation import ALS\n",
    "from pyspark.ml.regression import LinearRegression\n",
    "# from pyspark.graphframes import GraphFrame  # Graph processing library\n",
    "from pyspark.streaming import StreamingContext\n",
    "# from pyspark.sql.hive import HiveContext\n",
    "from pyspark.ml.pipeline import Pipeline\n",
    "from delta.tables import DeltaTable\n",
    "from pyspark.sql.functions import pandas_udf, PandasUDFType\n",
    "import unittest\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import Row\n",
    "from pyspark.sql.functions import col, lit, when, udf\n",
    "from pyspark import SparkContext\n",
    "from pyspark.ml import Estimator, Model\n",
    "from pyspark.ml.feature import VectorAssembler, StringIndexer\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import IntegerType, StringType\n",
    "from pyspark.sql import SQLContext\n",
    "from pyspark.sql import DataFrame\n",
    "\n",
    "\n",
    "# from openpyxl import Workbook\n",
    "# from openpyxl.styles import PatternFill, Border, Side\n",
    "# !pip install paramiko\n",
    "# log_information=[]\n",
    "# spark = SparkSession.builder \\\n",
    "#     .appName(\"HiveSupportExample\") \\\n",
    "#     .enableHiveSupport() \\\n",
    "#     .getOrCreate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7f63cdda-1cc6-484c-a03a-4a78d5c31ba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()  \n",
    "\n",
    "import pyspark\n",
    "import pandas as pd\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import lit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ac12aea1-0dd6-4c36-accc-2227174f7b92",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_string(df):\n",
    "    df.createOrReplaceTempView('temp_vw')\n",
    "    \n",
    "    string_columns = [col_name for col_name, col_type in df.dtypes if col_type == 'string']\n",
    "    \n",
    "    for col_name in string_columns:\n",
    "        spark.table('temp_vw') \\\n",
    "            .withColumn(\n",
    "                col_name,\n",
    "                trim(regexp_replace(col(col_name), \"[\\r\\n\\t\\\\xa0]\", \"\"))\n",
    "            ).createOrReplaceTempView('temp_vw')\n",
    "        \n",
    "        query = \", \".join(\n",
    "            [f\"regexp_replace({col_name}, '\\\\s+', ' ') as {col_name}\" if c == col_name else c for c in df.columns]\n",
    "        )\n",
    "        sql_query = f\"SELECT {query} FROM temp_vw\"\n",
    "        \n",
    "        spark.sql(sql_query).createOrReplaceTempView('temp_vw')\n",
    "    \n",
    "    # Return cleaned DataFrame\n",
    "    return spark.table('temp_vw')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "70794b72-ddc7-4d5c-9691-439fa6e2bdee",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'spark' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 10\u001b[0m\n\u001b[0;32m      1\u001b[0m data \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m      2\u001b[0m     {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m1\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m Alice \u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maddress\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMumbai\u001b[39m\u001b[38;5;130;01m\\r\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstatus\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m  Single\u001b[39m\u001b[38;5;130;01m\\xa0\u001b[39;00m\u001b[38;5;124m\"\u001b[39m},\n\u001b[0;32m      3\u001b[0m     {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m2\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m Bob \u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maddress\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDelhi\u001b[39m\u001b[38;5;130;01m\\xa0\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstatus\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMarried\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m\"\u001b[39m},\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m      6\u001b[0m     {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m5\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m Eve \u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maddress\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mKolkata\u001b[39m\u001b[38;5;130;01m\\r\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstatus\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m Married \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m}\n\u001b[0;32m      7\u001b[0m ]\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# Create DataFrame\u001b[39;00m\n\u001b[1;32m---> 10\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mspark\u001b[49m\u001b[38;5;241m.\u001b[39mcreateDataFrame(data)\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# Show the original DataFrame\u001b[39;00m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOriginal DataFrame:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'spark' is not defined"
     ]
    }
   ],
   "source": [
    "data = [\n",
    "    {\"id\": 1, \"name\": \" Alice \", \"address\": \"Mumbai\\r\\n\\t\", \"status\": \"  Single\\xa0\"},\n",
    "    {\"id\": 2, \"name\": \" Bob \", \"address\": \"Delhi\\xa0\\n\\t\", \"status\": \"Married\\n\\t\"},\n",
    "    {\"id\": 3, \"name\": \" Charlie \", \"address\": \"Bangalore\\t\", \"status\": \"  Single\\r\\n\"},\n",
    "    {\"id\": 4, \"name\": \" Diana \", \"address\": \"Chennai\\t\\r\", \"status\": \"Single\\xa0\"},\n",
    "    {\"id\": 5, \"name\": \" Eve \", \"address\": \"Kolkata\\r\\n\", \"status\": \" Married \\n\"}\n",
    "]\n",
    "\n",
    "# Create DataFrame\n",
    "df = spark.createDataFrame(data)\n",
    "\n",
    "# Show the original DataFrame\n",
    "print(\"Original DataFrame:\")\n",
    "df.show(truncate=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "979b6f36-01c9-4494-83c4-92e1248cc689",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m cleaned_df \u001b[38;5;241m=\u001b[39m clean_string(\u001b[43mdf\u001b[49m)\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCleaned DataFrame:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      3\u001b[0m cleaned_df\u001b[38;5;241m.\u001b[39mshow(truncate\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "cleaned_df = clean_string(df)\n",
    "print(\"Cleaned DataFrame:\")\n",
    "cleaned_df.show(truncate=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae4216d0-54f5-471e-9f0a-e6aa910c3912",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_df = clean_string(df)\n",
    "print(\"Cleaned DataFrame:\")\n",
    "cleaned_df.show(truncate=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
